"""
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘        PROJECT 1: RETAIL SALES PERFORMANCE ANALYSIS             â•‘
â•‘        Python | Pandas | NumPy | Matplotlib | Seaborn           â•‘
â•‘        Analysis Period: January 2023 - December 2024            â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

BUSINESS QUESTIONS WE WILL ANSWER:
Q1. What is the overall revenue performance and growth trend?
Q2. Which product categories drive the most revenue?
Q3. Which cities and regions are top performers?
Q4. What are the monthly and seasonal sales patterns?
Q5. Which products are the best and worst performers?
Q6. How do different sales channels compare?
Q7. What is the impact of discounts on revenue?
"""

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# SECTION 0: SETUP - Import libraries
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
import pandas as pd
import numpy as np
import matplotlib
matplotlib.use('Agg')  # Non-interactive backend
import matplotlib.pyplot as plt
import matplotlib.ticker as mticker
import seaborn as sns
import warnings
warnings.filterwarnings('ignore')

# Style settings - makes charts look professional
plt.rcParams['figure.figsize']  = (12, 6)
plt.rcParams['font.family']     = 'DejaVu Sans'
plt.rcParams['axes.spines.top']    = False
plt.rcParams['axes.spines.right']  = False
sns.set_palette("husl")

print("=" * 65)
print("  PROJECT 1: RETAIL SALES PERFORMANCE ANALYSIS")
print("=" * 65)
print("âœ“ Libraries loaded successfully\n")


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# SECTION 1: MORNING - Load & Explore Data
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
print("â”" * 65)
print("  SECTION 1: DATA LOADING & EXPLORATION")
print("â”" * 65)

# â”€â”€â”€ 1.1 Load the dataset â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
df = pd.read_csv('data/retail_sales_raw.csv')

print(f"\nğŸ“‚ Dataset loaded!")
print(f"   Shape: {df.shape[0]:,} rows Ã— {df.shape[1]} columns")

# â”€â”€â”€ 1.2 First look at data â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
print("\nğŸ“‹ First 5 rows:")
print(df.head().to_string())

# â”€â”€â”€ 1.3 Data types and structure â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
print("\nğŸ” Column Info:")
print(f"{'Column':<20} {'Dtype':<15} {'Non-Null Count':<15} {'Sample'}")
print("-" * 70)
for col in df.columns:
    dtype    = str(df[col].dtype)
    non_null = df[col].count()
    sample   = str(df[col].dropna().iloc[0]) if non_null > 0 else "N/A"
    print(f"{col:<20} {dtype:<15} {non_null:<15,} {sample[:30]}")

# â”€â”€â”€ 1.4 Statistical summary â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
print("\nğŸ“Š Statistical Summary (Numeric Columns):")
print(df.describe().round(2).to_string())

# â”€â”€â”€ 1.5 Missing values check â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
print("\nğŸ” Missing Values Check:")
missing = df.isnull().sum()
missing_pct = (missing / len(df) * 100).round(2)
missing_df = pd.DataFrame({'Missing Count': missing, 'Missing %': missing_pct})
missing_df = missing_df[missing_df['Missing Count'] > 0]
if len(missing_df) > 0:
    print(missing_df.to_string())
else:
    print("   No missing values found!")

# â”€â”€â”€ 1.6 Duplicates check â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
dupes = df.duplicated().sum()
print(f"\nğŸ” Duplicate Rows: {dupes:,}")

# â”€â”€â”€ 1.7 Unique value counts â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
print("\nğŸ” Unique Values per Category Column:")
cat_cols = ['category', 'city', 'customer_segment', 'payment_method', 'channel']
for col in cat_cols:
    uniq = df[col].nunique()
    vals = df[col].dropna().unique()[:5]
    print(f"   {col}: {uniq} unique â†’ {list(vals)}")

